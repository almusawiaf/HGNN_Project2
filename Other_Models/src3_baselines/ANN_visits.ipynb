{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, f1_score, roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((56465, 661), (56465, 203))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('../../Data/tabular/visit_level/X.npy')\n",
    "Y = np.load('../../Data/tabular/visit_level/Y.npy')\n",
    "\n",
    "X.shape, Y.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the top 10 frequent labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Y shape: (56465, 203)\n",
      "New Y shape with top 10 labels: (56465, 25)\n"
     ]
    }
   ],
   "source": [
    "num_Labels = 25\n",
    "\n",
    "label_frequencies = np.sum(Y, axis=0)\n",
    "\n",
    "top_10_labels_indices = np.argsort(label_frequencies)[-num_Labels:]  # Get indices of top 10 labels\n",
    "\n",
    "Y_top10 = Y[:, top_10_labels_indices]\n",
    "\n",
    "print(f\"Original Y shape: {Y.shape}\")\n",
    "print(f\"New Y shape with top 10 labels: {Y_top10.shape}\")\n",
    "\n",
    "Y = Y_top10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing observation with no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original X shape: (56465, 661)\n",
      "Original Y shape: (56465, 25)\n",
      "Filtered X shape: (53167, 661)\n",
      "Filtered Y shape: (53167, 25)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify rows where no labels are present (all zeros)\n",
    "rows_with_labels = np.sum(Y, axis=1) > 0\n",
    "\n",
    "# Step 2: Filter out these rows from both X and Y\n",
    "X_filtered = X[rows_with_labels]\n",
    "Y_filtered = Y[rows_with_labels]\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Original Y shape: {Y.shape}\")\n",
    "print(f\"Filtered X shape: {X_filtered.shape}\")\n",
    "print(f\"Filtered Y shape: {Y_filtered.shape}\")\n",
    "\n",
    "X, Y = X_filtered, Y_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_metrics(loss_history, metrics_history):\n",
    "    epochs = len(loss_history)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot loss on left y-axis with a distinct color (red)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss', color='tab:red')\n",
    "    ax1.plot(range(epochs), loss_history, color='tab:red', label='Loss', linewidth=2)\n",
    "    ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "    # Create a second y-axis for metrics\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.set_ylabel('Metrics', color='tab:blue')\n",
    "    \n",
    "    # Define distinct colors for each metric\n",
    "    metric_colors = ['tab:blue', 'tab:green', 'tab:orange', 'tab:purple', 'tab:brown', 'tab:pink']\n",
    "    \n",
    "    # Plot each metric with its own color\n",
    "    for i, (metric, values) in enumerate(metrics_history.items()):\n",
    "        ax2.plot(range(epochs), values, label=metric, color=metric_colors[i % len(metric_colors)], linewidth=2)\n",
    "\n",
    "    ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "    # Show legends for both loss and metrics\n",
    "    fig.tight_layout()\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax1.legend(loc='upper right')\n",
    "    plt.title('Loss and Metrics Over Epochs')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "def compute_metrics(y_true, y_pred, y_prob):\n",
    "    from sklearn.metrics import precision_score, f1_score, roc_auc_score, accuracy_score\n",
    "    metrics = {}\n",
    "    \n",
    "    # Micro precision\n",
    "    metrics['micro_precision'] = precision_score(y_true, y_pred, average='micro', zero_division=0)\n",
    "    \n",
    "    # Macro precision\n",
    "    metrics['macro_precision'] = precision_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # F1 Score\n",
    "    metrics['f1_score'] = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    \n",
    "    # Precision at k=4\n",
    "    top_k = torch.topk(y_prob, k=4, dim=1).indices\n",
    "    y_pred_at_k = torch.zeros_like(y_pred)\n",
    "    for i, row in enumerate(top_k):\n",
    "        y_pred_at_k[i, row] = 1\n",
    "    metrics['precision_at_k'] = precision_score(y_true, y_pred_at_k, average='micro', zero_division=0)\n",
    "    \n",
    "    # AUC\n",
    "    metrics['auc'] = roc_auc_score(y_true, y_prob, average='macro')\n",
    "    \n",
    "    # Accuracy\n",
    "    metrics['accuracy'] = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "# # Define the model\n",
    "# class MultilabelANN(nn.Module):\n",
    "#     def __init__(self, input_dim, output_dim):\n",
    "#         super(MultilabelANN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_dim, 512)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(512, 256)        # Second hidden layer\n",
    "#         self.fc3 = nn.Linear(256, output_dim) # Output layer\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.fc1(x))  # Apply ReLU on the first hidden layer\n",
    "#         x = self.relu(self.fc2(x))  # Apply ReLU on the second hidden layer\n",
    "#         x = self.sigmoid(self.fc3(x))  # Apply Sigmoid on the output layer\n",
    "#         return x\n",
    "    \n",
    "\n",
    "# 2. Adjust the model by adding extra layers and dropout\n",
    "class MultilabelANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultilabelANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout layer\n",
    "        self.fc4 = nn.Linear(128, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Function to plot label frequencies\n",
    "def plot_label_frequencies(Y):\n",
    "    # Sum the occurrences of each label across all samples (column-wise sum)\n",
    "    label_frequencies = np.sum(Y, axis=0)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(label_frequencies)), label_frequencies, color='skyblue')\n",
    "    plt.title('Label Frequency Distribution')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Assuming Y is your label matrix\n",
    "# Call the function to plot label frequencies\n",
    "plot_label_frequencies(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch [1/50], Loss: 0.3838, Micro Precision: 0.6631, Macro Precision: 0.4375, F1 Score: 0.2835, Precision at k=4: 0.4737, AUC: 0.7568, Accuracy: 0.0793\n",
      "Epoch [2/50], Loss: 0.3670, Micro Precision: 0.6763, Macro Precision: 0.5447, F1 Score: 0.2863, Precision at k=4: 0.4776, AUC: 0.7603, Accuracy: 0.0814\n",
      "Epoch [3/50], Loss: 0.3642, Micro Precision: 0.6643, Macro Precision: 0.5276, F1 Score: 0.3027, Precision at k=4: 0.4837, AUC: 0.7623, Accuracy: 0.0800\n",
      "Epoch [4/50], Loss: 0.3629, Micro Precision: 0.6803, Macro Precision: 0.5465, F1 Score: 0.3040, Precision at k=4: 0.4796, AUC: 0.7636, Accuracy: 0.0860\n",
      "Epoch [5/50], Loss: 0.3616, Micro Precision: 0.6853, Macro Precision: 0.5981, F1 Score: 0.2884, Precision at k=4: 0.4826, AUC: 0.7646, Accuracy: 0.0842\n",
      "Epoch [6/50], Loss: 0.3608, Micro Precision: 0.6817, Macro Precision: 0.5501, F1 Score: 0.2979, Precision at k=4: 0.4830, AUC: 0.7643, Accuracy: 0.0820\n",
      "Epoch [7/50], Loss: 0.3600, Micro Precision: 0.6805, Macro Precision: 0.5486, F1 Score: 0.2981, Precision at k=4: 0.4821, AUC: 0.7636, Accuracy: 0.0858\n",
      "Epoch [8/50], Loss: 0.3595, Micro Precision: 0.6704, Macro Precision: 0.5703, F1 Score: 0.3029, Precision at k=4: 0.4803, AUC: 0.7638, Accuracy: 0.0835\n",
      "Epoch [9/50], Loss: 0.3588, Micro Precision: 0.6776, Macro Precision: 0.5887, F1 Score: 0.3011, Precision at k=4: 0.4825, AUC: 0.7640, Accuracy: 0.0821\n",
      "Epoch [10/50], Loss: 0.3585, Micro Precision: 0.6789, Macro Precision: 0.5730, F1 Score: 0.3045, Precision at k=4: 0.4816, AUC: 0.7629, Accuracy: 0.0829\n",
      "Epoch [11/50], Loss: 0.3579, Micro Precision: 0.6766, Macro Precision: 0.5741, F1 Score: 0.2941, Precision at k=4: 0.4805, AUC: 0.7626, Accuracy: 0.0818\n",
      "Epoch [12/50], Loss: 0.3571, Micro Precision: 0.6845, Macro Precision: 0.5885, F1 Score: 0.3011, Precision at k=4: 0.4829, AUC: 0.7641, Accuracy: 0.0827\n",
      "Epoch [13/50], Loss: 0.3566, Micro Precision: 0.6682, Macro Precision: 0.5767, F1 Score: 0.3036, Precision at k=4: 0.4815, AUC: 0.7637, Accuracy: 0.0839\n",
      "Epoch [14/50], Loss: 0.3561, Micro Precision: 0.6484, Macro Precision: 0.5745, F1 Score: 0.3221, Precision at k=4: 0.4811, AUC: 0.7624, Accuracy: 0.0836\n",
      "Epoch [15/50], Loss: 0.3560, Micro Precision: 0.6764, Macro Precision: 0.5720, F1 Score: 0.3027, Precision at k=4: 0.4791, AUC: 0.7630, Accuracy: 0.0832\n",
      "Epoch [16/50], Loss: 0.3556, Micro Precision: 0.6635, Macro Precision: 0.5670, F1 Score: 0.3144, Precision at k=4: 0.4815, AUC: 0.7628, Accuracy: 0.0828\n",
      "Epoch [17/50], Loss: 0.3552, Micro Precision: 0.6754, Macro Precision: 0.6384, F1 Score: 0.3034, Precision at k=4: 0.4812, AUC: 0.7624, Accuracy: 0.0808\n",
      "Epoch [18/50], Loss: 0.3550, Micro Precision: 0.6705, Macro Precision: 0.5794, F1 Score: 0.3030, Precision at k=4: 0.4796, AUC: 0.7621, Accuracy: 0.0818\n",
      "Epoch [19/50], Loss: 0.3546, Micro Precision: 0.6700, Macro Precision: 0.5769, F1 Score: 0.3103, Precision at k=4: 0.4814, AUC: 0.7626, Accuracy: 0.0842\n",
      "Epoch [20/50], Loss: 0.3538, Micro Precision: 0.6515, Macro Precision: 0.5711, F1 Score: 0.3277, Precision at k=4: 0.4806, AUC: 0.7622, Accuracy: 0.0826\n",
      "Epoch [21/50], Loss: 0.3537, Micro Precision: 0.6542, Macro Precision: 0.5767, F1 Score: 0.3199, Precision at k=4: 0.4798, AUC: 0.7614, Accuracy: 0.0812\n",
      "Epoch [22/50], Loss: 0.3533, Micro Precision: 0.6639, Macro Precision: 0.5645, F1 Score: 0.3060, Precision at k=4: 0.4807, AUC: 0.7618, Accuracy: 0.0830\n",
      "Epoch [23/50], Loss: 0.3529, Micro Precision: 0.6567, Macro Precision: 0.5816, F1 Score: 0.3156, Precision at k=4: 0.4794, AUC: 0.7607, Accuracy: 0.0833\n",
      "Epoch [24/50], Loss: 0.3526, Micro Precision: 0.6624, Macro Precision: 0.5635, F1 Score: 0.3119, Precision at k=4: 0.4801, AUC: 0.7611, Accuracy: 0.0828\n",
      "Epoch [25/50], Loss: 0.3523, Micro Precision: 0.6609, Macro Precision: 0.5691, F1 Score: 0.3055, Precision at k=4: 0.4802, AUC: 0.7604, Accuracy: 0.0815\n",
      "Epoch [26/50], Loss: 0.3524, Micro Precision: 0.6536, Macro Precision: 0.5852, F1 Score: 0.3160, Precision at k=4: 0.4783, AUC: 0.7610, Accuracy: 0.0830\n",
      "Epoch [27/50], Loss: 0.3519, Micro Precision: 0.6731, Macro Precision: 0.5693, F1 Score: 0.3095, Precision at k=4: 0.4800, AUC: 0.7619, Accuracy: 0.0806\n",
      "Epoch [28/50], Loss: 0.3514, Micro Precision: 0.6630, Macro Precision: 0.5934, F1 Score: 0.3187, Precision at k=4: 0.4801, AUC: 0.7628, Accuracy: 0.0813\n",
      "Epoch [29/50], Loss: 0.3514, Micro Precision: 0.6840, Macro Precision: 0.6125, F1 Score: 0.2970, Precision at k=4: 0.4806, AUC: 0.7607, Accuracy: 0.0828\n",
      "Epoch [30/50], Loss: 0.3514, Micro Precision: 0.6643, Macro Precision: 0.5707, F1 Score: 0.3092, Precision at k=4: 0.4820, AUC: 0.7617, Accuracy: 0.0840\n",
      "Epoch [31/50], Loss: 0.3507, Micro Precision: 0.6640, Macro Precision: 0.5690, F1 Score: 0.3076, Precision at k=4: 0.4812, AUC: 0.7609, Accuracy: 0.0837\n",
      "Epoch [32/50], Loss: 0.3506, Micro Precision: 0.6595, Macro Precision: 0.5740, F1 Score: 0.3099, Precision at k=4: 0.4810, AUC: 0.7605, Accuracy: 0.0795\n",
      "Epoch [33/50], Loss: 0.3504, Micro Precision: 0.6791, Macro Precision: 0.6004, F1 Score: 0.3020, Precision at k=4: 0.4800, AUC: 0.7606, Accuracy: 0.0830\n",
      "Epoch [34/50], Loss: 0.3498, Micro Precision: 0.6537, Macro Precision: 0.5625, F1 Score: 0.3159, Precision at k=4: 0.4814, AUC: 0.7603, Accuracy: 0.0836\n",
      "Epoch [35/50], Loss: 0.3495, Micro Precision: 0.6441, Macro Precision: 0.5680, F1 Score: 0.3218, Precision at k=4: 0.4778, AUC: 0.7600, Accuracy: 0.0849\n",
      "Epoch [36/50], Loss: 0.3495, Micro Precision: 0.6537, Macro Precision: 0.5675, F1 Score: 0.3173, Precision at k=4: 0.4790, AUC: 0.7593, Accuracy: 0.0829\n",
      "Epoch [37/50], Loss: 0.3493, Micro Precision: 0.6515, Macro Precision: 0.5502, F1 Score: 0.3157, Precision at k=4: 0.4776, AUC: 0.7594, Accuracy: 0.0808\n",
      "Epoch [38/50], Loss: 0.3491, Micro Precision: 0.6504, Macro Precision: 0.5595, F1 Score: 0.3242, Precision at k=4: 0.4775, AUC: 0.7579, Accuracy: 0.0826\n",
      "Epoch [39/50], Loss: 0.3490, Micro Precision: 0.6513, Macro Precision: 0.5656, F1 Score: 0.3131, Precision at k=4: 0.4786, AUC: 0.7586, Accuracy: 0.0834\n",
      "Epoch [40/50], Loss: 0.3486, Micro Precision: 0.6462, Macro Precision: 0.5674, F1 Score: 0.3194, Precision at k=4: 0.4769, AUC: 0.7590, Accuracy: 0.0812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Step 0: Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Split the data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Convert data to PyTorch tensors and move to GPU if available\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32).to(device)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Step 3: Model initialization and move to GPU\n",
    "input_dim = X_train.shape[1]  # 661 features\n",
    "output_dim = Y_train.shape[1]  # 203 labels\n",
    "model = MultilabelANN(input_dim, output_dim).to(device)\n",
    "\n",
    "# Step 4: Define loss and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multilabel classification\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Step 5: Training loop parameters\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "\n",
    "# Step 6: Create DataLoader for batching the training data\n",
    "train_data = torch.utils.data.TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Step 7: Training loop with metric calculation and plotting\n",
    "loss_history = []\n",
    "metrics_history = {\n",
    "    'micro_precision': [],\n",
    "    'macro_precision': [],\n",
    "    'f1_score': [],\n",
    "    'precision_at_k': [],\n",
    "    'auc': [],\n",
    "    'accuracy': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss for this batch\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    \n",
    "    # Evaluation and metrics computation\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = X_test_tensor.to(device)\n",
    "        Y_test_tensor = Y_test_tensor.to(device)\n",
    "        outputs = model(X_test_tensor)\n",
    "        \n",
    "        # Convert outputs to binary predictions (multilabel)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        # Compute metrics\n",
    "        metrics = compute_metrics(Y_test, predicted, outputs)\n",
    "        \n",
    "        # Store metrics for plotting\n",
    "        for key in metrics_history:\n",
    "            metrics_history[key].append(metrics[key])\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, \"\n",
    "          f\"Micro Precision: {metrics['micro_precision']:.4f}, \"\n",
    "          f\"Macro Precision: {metrics['macro_precision']:.4f}, \"\n",
    "          f\"F1 Score: {metrics['f1_score']:.4f}, \"\n",
    "          f\"Precision at k=4: {metrics['precision_at_k']:.4f}, \"\n",
    "          f\"AUC: {metrics['auc']:.4f}, \"\n",
    "          f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "# Step 8: Plot the loss and metrics\n",
    "plot_metrics(loss_history, metrics_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# import torch\n",
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "\n",
    "# # Step 1: Split the data into train and test sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Step 2: Convert data to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# Y_train_tensor = torch.tensor(Y_train, dtype=torch.float32)\n",
    "# Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# # Step 3: Model initialization\n",
    "# input_dim = X_train.shape[1]  # 661 features\n",
    "# output_dim = Y_train.shape[1]  # 203 labels\n",
    "# model = MultilabelANN(input_dim, output_dim)\n",
    "\n",
    "# # Step 4: Define loss and optimizer\n",
    "# criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multilabel classification\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# # Step 5: Training loop parameters\n",
    "# num_epochs = 20\n",
    "# batch_size = 64\n",
    "\n",
    "# # Step 6: Create DataLoader for batching the training data\n",
    "# train_data = torch.utils.data.TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Step 7: Training loop with metric calculation and plotting\n",
    "# loss_history = []\n",
    "# metrics_history = {\n",
    "#     'micro_precision': [],\n",
    "#     'macro_precision': [],\n",
    "#     'f1_score': [],\n",
    "#     'precision_at_k': [],\n",
    "#     'auc': [],\n",
    "#     'accuracy': []\n",
    "# }\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()  # Set model to training mode\n",
    "#     running_loss = 0.0\n",
    "#     for i, (inputs, labels) in enumerate(train_loader):\n",
    "#         # Zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         # Backward pass and optimization\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         # Accumulate loss for this batch\n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = running_loss / len(train_loader)\n",
    "#     loss_history.append(avg_loss)\n",
    "    \n",
    "#     # Evaluation and metrics computation\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X_test_tensor)\n",
    "        \n",
    "#         # Convert outputs to binary predictions (multilabel)\n",
    "#         predicted = (outputs > 0.5).float()\n",
    "        \n",
    "#         # Compute metrics\n",
    "#         metrics = compute_metrics(Y_test, predicted, outputs)\n",
    "        \n",
    "#         # Store metrics for plotting\n",
    "#         for key in metrics_history:\n",
    "#             metrics_history[key].append(metrics[key])\n",
    "    \n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, \"\n",
    "#           f\"Micro Precision: {metrics['micro_precision']:.4f}, \"\n",
    "#           f\"Macro Precision: {metrics['macro_precision']:.4f}, \"\n",
    "#           f\"F1 Score: {metrics['f1_score']:.4f}, \"\n",
    "#           f\"Precision at k=4: {metrics['precision_at_k']:.4f}, \"\n",
    "#           f\"AUC: {metrics['auc']:.4f}, \"\n",
    "#           f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "# # Step 8: Plot the loss and metrics\n",
    "# plot_metrics(loss_history, metrics_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# # Function to apply RandomOverSampler to the entire dataset, resampling all labels simultaneously\n",
    "# def apply_random_oversampling(X, Y):\n",
    "#     ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "    \n",
    "#     # Flatten the Y matrix into a 1D array of tuples to retain the multilabel structure during resampling\n",
    "#     Y_flattened = [''.join(map(str, y)) for y in Y]  # Convert each row into a string (e.g., '001')\n",
    "    \n",
    "#     # Resample the dataset based on the flattened labels\n",
    "#     X_resampled, Y_resampled_flattened = ros.fit_resample(X, Y_flattened)\n",
    "    \n",
    "#     # Convert the flattened labels back to their original multilabel format\n",
    "#     Y_resampled = np.array([list(map(int, y)) for y in Y_resampled_flattened])\n",
    "    \n",
    "#     return X_resampled, Y_resampled\n",
    "\n",
    "# # Step 1: Split the data into train and test sets\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Step 2: Apply RandomOverSampler to the entire training dataset\n",
    "# X_train_resampled, Y_train_resampled = apply_random_oversampling(X_train, Y_train)\n",
    "\n",
    "# # Step 3: Convert the resampled data to PyTorch tensors\n",
    "# X_train_tensor = torch.tensor(X_train_resampled, dtype=torch.float32)\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# Y_train_tensor = torch.tensor(Y_train_resampled, dtype=torch.float32)\n",
    "# Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32)\n",
    "\n",
    "# # Continue with model training as before\n",
    "# input_dim = X_train.shape[1]  # 661 features\n",
    "# output_dim = Y_train.shape[1]  # 203 labels\n",
    "# model = MultilabelANN(input_dim, output_dim)\n",
    "\n",
    "# # Define loss and optimizer\n",
    "# criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for multilabel classification\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Training loop parameters\n",
    "# num_epochs = 20\n",
    "# batch_size = 64\n",
    "\n",
    "# # Create DataLoader for batching the resampled training data\n",
    "# train_data = torch.utils.data.TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# # Training loop (rest of the code remains the same)\n",
    "# loss_history = []\n",
    "# metrics_history = {\n",
    "#     'micro_precision': [],\n",
    "#     'macro_precision': [],\n",
    "#     'f1_score': [],\n",
    "#     'precision_at_k': [],\n",
    "#     'auc': [],\n",
    "#     'accuracy': []\n",
    "# }\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     avg_loss = running_loss / len(train_loader)\n",
    "#     loss_history.append(avg_loss)\n",
    "    \n",
    "#     # Evaluation\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(X_test_tensor)\n",
    "#         predicted = (outputs > 0.5).float()\n",
    "        \n",
    "#         metrics = compute_metrics(Y_test, predicted, outputs)\n",
    "#         for key in metrics_history:\n",
    "#             metrics_history[key].append(metrics[key])\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, \"\n",
    "#           f\"Micro Precision: {metrics['micro_precision']:.4f}, \"\n",
    "#           f\"Macro Precision: {metrics['macro_precision']:.4f}, \"\n",
    "#           f\"F1 Score: {metrics['f1_score']:.4f}, \"\n",
    "#           f\"Precision at k=4: {metrics['precision_at_k']:.4f}, \"\n",
    "#           f\"AUC: {metrics['auc']:.4f}, \"\n",
    "#           f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "\n",
    "# # After training, plot loss and metrics as usual\n",
    "# plot_metrics(loss_history, metrics_history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
