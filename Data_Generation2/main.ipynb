{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of diseases (labels) = 203\n",
      "Disease File = DMPLB2\n",
      "similarity_type = PC\n",
      "num_Sample = 500\n",
      "sampling = True\n",
      "../Data/203_Diagnoses/DMPLB2/500/HGNN_data\n",
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46517\n",
      "Number of Visits = 58929\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "Number of Lab tests  = 993\n",
      "Number of MicroBio   = 65\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Extracting bipartite networks...\n",
      "\n",
      "Extracting and adding data of Visits\n",
      "\n",
      "Extracting and adding data of Diagnosis\n",
      "\n",
      "Extracting and adding data of Procedures\n",
      "\n",
      "Extracting and adding data of Medications\n",
      "\n",
      "Extracting and adding data of Lab tests\n",
      "\n",
      "Extracting and adding data of MicroBiology tests\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 993\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5360286\n",
      "------------------------------------------\n",
      "\n",
      "Removing isolated nodes\n",
      "Number of PATIENTS to remove: 0\n",
      "Number of nodes to remove: 0\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "45937 500 46437\n",
      "Number of PATIENTS to remove: 45937\n",
      "Number of nodes to remove: 104120\n",
      "number of patients = 500\n",
      "number of visits = 746\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 61226\n",
      "------------------------------------------\n",
      "\n",
      "Number of rows with zero sum: 6\n",
      "Number of PATIENTS to remove: 6\n",
      "Number of nodes to remove: 18\n",
      "getting the feature set for all nodes\n",
      "Create a new One Hot vector per node\n",
      "extracting As from HG\n",
      "\n",
      "=============================================================\n",
      "Patients:\n",
      "\tWorking on: Patient-Medication\n",
      "\tWorking on: Patient-Diagnosis\n",
      "\tWorking on: Patient-Procedure\n",
      "\tWorking on: Patient-Lab\n",
      "\tWorking on: Patient-MicroBiology\n",
      "Diagnoses:\n",
      "\tWorking on: Diagnosis-Medication\n",
      "\tWorking on: Diagnosis-Procedure\n",
      "\tWorking on: Diagnosis-Lab\n",
      "\tWorking on: Diagnosis-MicroBiology\n",
      "Procedures:\n",
      "\tWorking on: Procedure-Medication\n",
      "\tWorking on: Procedure-Lab\n",
      "\tWorking on: Procedure-MicroBiology\n",
      "\tWorking on: Medication-Lab\n",
      "\tWorking on: Medication-MicroBiology\n",
      "\tWorking on: Lab-MicroBiology\n",
      "Homogeneous similarity\n",
      "1. Patient-Patient\n",
      "\tWorking on: Patient-Visit-Medication-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Diagnosis-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Procedure-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Lab-Visit-Patient\n",
      "\tWorking on: Patient-Visit-MicroBiology-Visit-Patient\n",
      "2. visit-visit\n",
      "\tWorking on: Visit-Medication-Visit\n",
      "\tWorking on: Visit-Diagnosis-Visit\n",
      "\tWorking on: Visit-Procedure-Visit\n",
      "\tWorking on: Visit-Lab-Visit\n",
      "\tWorking on: Visit-MicroBiology-Visit\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/HGNN_data/As/metapath_list.pkl\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/GMLs/Nodes.pkl\n",
      "Measure the similarity, expand it and save to PSGs/M.npz\n",
      "Getting the OHV for M\n",
      "Measure the similarity, expand it and save to PSGs/D.npz\n",
      "Getting the OHV for D\n",
      "Measure the similarity, expand it and save to PSGs/P.npz\n",
      "Getting the OHV for P\n",
      "Measure the similarity, expand it and save to PSGs/L.npz\n",
      "Getting the OHV for L\n",
      "Measure the similarity, expand it and save to PSGs/B.npz\n",
      "Getting the OHV for B\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/PSGs/PSGs_List.pkl\n",
      "Matrix 0: 609 non-zero elements\n",
      "\tSaving all non-zero values... (609 non-zero elements)\n",
      "Matrix 1: 0 non-zero elements\n",
      "Matrix 1 has zero values. Not saving...\n",
      "Matrix 2: 5494 non-zero elements\n",
      "\tSaving all non-zero values... (5494 non-zero elements)\n",
      "Matrix 3: 1864 non-zero elements\n",
      "\tSaving all non-zero values... (1864 non-zero elements)\n",
      "Matrix 4: 52105 non-zero elements\n",
      "\tSaving all non-zero values... (52105 non-zero elements)\n",
      "Matrix 5: 382 non-zero elements\n",
      "\tSaving all non-zero values... (382 non-zero elements)\n",
      "Matrix 6: 0 non-zero elements\n",
      "Matrix 6 has zero values. Not saving...\n",
      "Matrix 7: 4900 non-zero elements\n",
      "\tSaving all non-zero values... (4900 non-zero elements)\n",
      "Matrix 8: 1572 non-zero elements\n",
      "\tSaving all non-zero values... (1572 non-zero elements)\n",
      "Matrix 9: 39808 non-zero elements\n",
      "\tSaving all non-zero values... (39808 non-zero elements)\n",
      "Matrix 10: 319 non-zero elements\n",
      "\tSaving all non-zero values... (319 non-zero elements)\n",
      "Matrix 11: 0 non-zero elements\n",
      "Matrix 11 has zero values. Not saving...\n",
      "Matrix 12: 4149 non-zero elements\n",
      "\tSaving all non-zero values... (4149 non-zero elements)\n",
      "Matrix 13: 49822 non-zero elements\n",
      "\tSaving all non-zero values... (49822 non-zero elements)\n",
      "Matrix 14: 1309 non-zero elements\n",
      "\tSaving all non-zero values... (1309 non-zero elements)\n",
      "Matrix 15: 0 non-zero elements\n",
      "Matrix 15 has zero values. Not saving...\n",
      "Matrix 16: 15349 non-zero elements\n",
      "\tSaving all non-zero values... (15349 non-zero elements)\n",
      "Matrix 17: 466 non-zero elements\n",
      "\tSaving all non-zero values... (466 non-zero elements)\n",
      "Matrix 18: 0 non-zero elements\n",
      "Matrix 18 has zero values. Not saving...\n",
      "Matrix 19: 0 non-zero elements\n",
      "Matrix 19 has zero values. Not saving...\n",
      "Matrix 20: 0 non-zero elements\n",
      "Matrix 20 has zero values. Not saving...\n",
      "Matrix 21: 0 non-zero elements\n",
      "Matrix 21 has zero values. Not saving...\n",
      "Matrix 22: 61740 non-zero elements\n",
      "\tSaving all non-zero values... (61740 non-zero elements)\n",
      "Matrix 23: 48415 non-zero elements\n",
      "\tSaving all non-zero values... (48415 non-zero elements)\n",
      "Matrix 24: 118542 non-zero elements\n",
      "\tSaving all non-zero values... (118542 non-zero elements)\n",
      "Matrix 25: 6752 non-zero elements\n",
      "\tSaving all non-zero values... (6752 non-zero elements)\n",
      "Matrix 26: 0 non-zero elements\n",
      "Matrix 26 has zero values. Not saving...\n",
      "Matrix 27: 103739 non-zero elements\n",
      "\tSaving all non-zero values... (103739 non-zero elements)\n",
      "Matrix 28: 73168 non-zero elements\n",
      "\tSaving all non-zero values... (73168 non-zero elements)\n",
      "Matrix 29: 326080 non-zero elements\n",
      "\tSaving all non-zero values... (326080 non-zero elements)\n",
      "Matrix 30: 10283 non-zero elements\n",
      "\tSaving all non-zero values... (10283 non-zero elements)\n",
      "Matrix 31: 6752 non-zero elements\n",
      "\tSaving all non-zero values... (6752 non-zero elements)\n",
      "Matrix 32: 61740 non-zero elements\n",
      "\tSaving all non-zero values... (61740 non-zero elements)\n",
      "Matrix 33: 118542 non-zero elements\n",
      "\tSaving all non-zero values... (118542 non-zero elements)\n",
      "Matrix 34: 0 non-zero elements\n",
      "Matrix 34 has zero values. Not saving...\n",
      "Matrix 35: 48415 non-zero elements\n",
      "\tSaving all non-zero values... (48415 non-zero elements)\n",
      "done saving [unique edges]:  696152\n",
      "Working on 0th file (cv)...\n",
      "Working on 1th file (vd)...\n",
      "Working on 2th file (vp)...\n",
      "Working on 3th file (vl)...\n",
      "Working on 4th file (vb)...\n",
      "Working on 5th file (cvd)...\n",
      "Working on 6th file (cvp)...\n",
      "Working on 7th file (cvl)...\n",
      "Working on 8th file (cvb)...\n",
      "Working on 9th file (dvp)...\n",
      "Working on 10th file (dvl)...\n",
      "Working on 11th file (dvb)...\n",
      "Working on 12th file (pvl)...\n",
      "Working on 13th file (pvb)...\n",
      "Working on 14th file (cvdvc)...\n",
      "Working on 15th file (cvpvc)...\n",
      "Working on 16th file (cvlvc)...\n",
      "Working on 17th file (cvbvc)...\n",
      "Working on 18th file (vdv)...\n",
      "Working on 19th file (vpv)...\n",
      "Working on 20th file (vlv)...\n",
      "Working on 21th file (vbv)...\n",
      "Working on 22th file (M)...\n",
      "Working on 23th file (D)...\n",
      "Working on 24th file (P)...\n",
      "Working on 25th file (B)...\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/HGNN_data//edges/final_meta_paths.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module1.reduction.Reduction at 0x7f3958e37ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Function to save a list as a pickle file\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n",
    "\n",
    "def load_dict_from_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_dict = pickle.load(file)\n",
    "    return loaded_dict  \n",
    "\n",
    "# Class representing a heterogeneous graph\n",
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G        \n",
    "        HG_Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in HG_Nodes if v[0] == 'C']\n",
    "        self.Visits =      [v for v in HG_Nodes if v[0] == 'V']\n",
    "        self.Medications = [v for v in HG_Nodes if v[0] == 'M']\n",
    "        self.Diagnosis  =  [v for v in HG_Nodes if v[0] == 'D']\n",
    "        self.Procedures =  [v for v in HG_Nodes if v[0] == 'P']\n",
    "        self.Labs       =  [v for v in HG_Nodes if v[0] == 'L']\n",
    "        self.MicroBio   =  [v for v in HG_Nodes if v[0] == 'B']\n",
    "        self.Nodes = self.Patients + self.Visits + self.Medications + self.Diagnosis + self.Procedures + self.Labs + self.MicroBio\n",
    "\n",
    "# Example code snippet using environment variables\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path', '../../MIMIC_resources')\n",
    "disease_data_path = os.getenv('disease_data_path', '../Data')\n",
    "num_Diseases      = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE      = os.getenv('DISEASE_FILE', 'DMPLB2')  \n",
    "similarity_type   = os.getenv('similarity_type', 'PC')  # options: PC, SPS\n",
    "num_Sample        = int(os.getenv('num_Sample', 500))  \n",
    "r_u_sampling      = os.getenv('r_u_sampling', 'True')  \n",
    "PSGs_ing          = os.getenv('PSGs_ing', 'True')\n",
    "\n",
    "# Convert string flags to boolean\n",
    "sampling = r_u_sampling == 'True'\n",
    "PSGs_ing = PSGs_ing == 'True'\n",
    "\n",
    "# Print the settings\n",
    "print(f'number of diseases (labels) = {num_Diseases}\\nDisease File = {DISEASE_FILE}\\nsimilarity_type = {similarity_type}\\nnum_Sample = {num_Sample}\\nsampling = {sampling}')\n",
    "\n",
    "# Define the base path for saving data\n",
    "base_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "# Create necessary directories\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs']:\n",
    "    os.makedirs(f'{base_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{base_path}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "os.makedirs(f'{saving_path}/edges', exist_ok=True)\n",
    "\n",
    "# Print the saving path\n",
    "print(saving_path)\n",
    "\n",
    "\n",
    "from module1 import generating_HG as gHG\n",
    "\n",
    "# Generating the heterogeneous graph (HG)\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "\n",
    "# Save the HG as a GML file\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "\n",
    "# Print the graph's statistics\n",
    "gHG.G_statistics(HG_inst.HG)\n",
    "# ===========================================================================================\n",
    "# Sampling or working with the whole graph\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    final_HG = HG_inst.HG\n",
    "else:\n",
    "    # Randomly sample patients to remove\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # Remove patients and linked visits\n",
    "    final_HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "\n",
    "# Create a new HG instance for the sampled graph\n",
    "HG_obj = heterogeneous_Graph(final_HG)\n",
    "\n",
    "# Print statistics for the new graph\n",
    "gHG.G_statistics(HG_obj.HG)\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import XY_preparation as XY\n",
    "\n",
    "# Extract patient-based X and Y\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "final_HG = XY_inst.HG\n",
    "\n",
    "# Save the feature set X and labels Y\n",
    "torch.save(X, f'{base_path}/OHV/X.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/Y.pt')\n",
    "\n",
    "# Clean up memory\n",
    "del X\n",
    "del Y\n",
    "\n",
    "# Extract and save superclasses\n",
    "YY = XY_inst.get_Y_superclasses()\n",
    "torch.save(YY, f'{base_path}/OHV/Ysuperclass.pt')\n",
    "del YY\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import meta_path_2 as MP\n",
    "\n",
    "# Compute the meta-path-based similarities\n",
    "MP_inst = MP.Meta_path(final_HG, similarity_type='PC', saving_path=saving_path)\n",
    "\n",
    "# Save the heterogeneous graph in GML format\n",
    "nx.write_gml(final_HG, f'{base_path}/GMLs/HG.gml')\n",
    "\n",
    "# Save the nodes\n",
    "save_list_as_pickle(MP_inst.Nodes, f'{base_path}/GMLs', 'Nodes')\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import patients_sim as PS   \n",
    "\n",
    "# Create a new heterogeneous graph instance\n",
    "HG_obj2 = heterogeneous_Graph(final_HG)\n",
    "\n",
    "# Compute and save patient similarity\n",
    "PS.Patients_Similarity(HG_obj2.HG, HG_obj2.Nodes, base_path)\n",
    "# ===========================================================================================\n",
    "from module1 import reduction as Red\n",
    "\n",
    "# Reduce and save the meta-path similarity matrices\n",
    "Red.Reduction(base_path, PSGs=PSGs_ing)\n",
    "\n",
    "# ===========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric Difference: ['pvm', 'lvb', 'dvm', 'cvmvc', 'P', 'mvl', 'M', 'D', 'cvm', 'mvb', 'vmv', 'B', 'vm']\n"
     ]
    }
   ],
   "source": [
    "def load_dict_from_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_dict = pickle.load(file)\n",
    "    return loaded_dict  \n",
    "b = load_dict_from_pickle('../Data/203_Diagnoses/DMPLB2/500/HGNN_data/edges/final_meta_paths.pkl')\n",
    "a = load_dict_from_pickle('../Data/203_Diagnoses/DMPLB2/500/HGNN_data/As/metapath_list.pkl')\n",
    "\n",
    "symmetric_diff = list(set(a).symmetric_difference(set(b)))\n",
    "print(\"Symmetric Difference:\", symmetric_diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv',\n",
       " 'vm',\n",
       " 'vd',\n",
       " 'vp',\n",
       " 'vl',\n",
       " 'vb',\n",
       " 'cvm',\n",
       " 'cvd',\n",
       " 'cvp',\n",
       " 'cvl',\n",
       " 'cvb',\n",
       " 'dvm',\n",
       " 'dvp',\n",
       " 'dvl',\n",
       " 'dvb',\n",
       " 'pvm',\n",
       " 'pvl',\n",
       " 'pvb',\n",
       " 'mvl',\n",
       " 'mvb',\n",
       " 'lvb',\n",
       " 'cvmvc',\n",
       " 'cvdvc',\n",
       " 'cvpvc',\n",
       " 'cvlvc',\n",
       " 'cvbvc',\n",
       " 'vmv',\n",
       " 'vdv',\n",
       " 'vpv',\n",
       " 'vlv',\n",
       " 'vbv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cv',\n",
       " 'vd',\n",
       " 'vp',\n",
       " 'vl',\n",
       " 'vb',\n",
       " 'cvd',\n",
       " 'cvp',\n",
       " 'cvl',\n",
       " 'cvb',\n",
       " 'dvp',\n",
       " 'dvl',\n",
       " 'dvb',\n",
       " 'pvl',\n",
       " 'pvb',\n",
       " 'cvdvc',\n",
       " 'cvpvc',\n",
       " 'cvlvc',\n",
       " 'cvbvc',\n",
       " 'vdv',\n",
       " 'vpv',\n",
       " 'vlv',\n",
       " 'vbv',\n",
       " 'M',\n",
       " 'D',\n",
       " 'P',\n",
       " 'B']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
