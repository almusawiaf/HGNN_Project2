{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "1. Generate the Heterogeneous graph\n",
    "2. Generate the feature set and labels.\n",
    "3. Generate the k-metapath-based similarity matrices\n",
    "4. Reduce and Convert the As to edge-list based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    import pickle\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G\n",
    "        Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in Nodes if v[0]=='C']\n",
    "        self.Visits =      [v for v in Nodes if v[0]=='V']\n",
    "        self.Medications = [v for v in Nodes if v[0]=='M']\n",
    "        self.Diagnoses  =  [v for v in Nodes if v[0]=='D']\n",
    "        self.Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "        self.Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "        self.MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "        self.Nodes = self.Patients  + self.Visits + self.Medications + self.Diagnoses + self.Procedures + self.Labs + self.MicroBio\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # OAK :-)\n",
    "# MIMIC_Path        = os.getenv('MIMIC_Path',        '/home/almusawiaf/MyDocuments/PhD_Projects/Data/MIMIC_resources')\n",
    "\n",
    "# Check for Athena :-(\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path', '../../MIMIC_resources')\n",
    "\n",
    "disease_data_path = os.getenv('disease_data_path', '../Data')\n",
    "\n",
    "num_Diseases    = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE    = os.getenv('DISEASE_FILE', f'DMPLB2')  \n",
    "similarity_type = os.getenv('similarity_type', 'PC')  # options are PC: PathCount, SPS: Symmetric PathSim\n",
    "\n",
    "num_Sample      = int(os.getenv('num_Sample', 250))  \n",
    "r_u_sampling    = os.getenv('r_u_sampling', 'True')  \n",
    "PSGs_ing        = os.getenv('PSGs_ing', 'False')  \n",
    "\n",
    "\n",
    "if r_u_sampling=='True':\n",
    "    sampling = True\n",
    "else:\n",
    "    sampling = False\n",
    "\n",
    "if PSGs_ing=='True':\n",
    "    PSGs_ing = True\n",
    "else:\n",
    "    PSGs_ing = False\n",
    "\n",
    "print(num_Diseases, DISEASE_FILE, similarity_type, num_Sample, sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "base_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs', 'SNFs']:\n",
    "    os.makedirs(f'{base_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{base_path}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "os.makedirs(f'{saving_path}/edges', exist_ok=True)\n",
    "# =================================================================================\n",
    "print(saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating complete HG from scratch\n",
    "- HG_inst: is an object that holds the heterogeneous graph information such as the graph (HG), Nodes, separated lists for the different types of nodes (Patients, visits, diagnoses, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import generating_HG as gHG\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "gHG.G_statistics(HG_inst.HG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole graph / Sample graph / Selected Patients only?\n",
    "\n",
    "- Do we want to work on the entire graph or a sample of graph?\n",
    "- We can create our own graph accordingly, for example: \n",
    "    - Identifying specific set of patients to keep\n",
    "    - Identifying the rest of patients to remove,\n",
    "    - call the  **remove_patients_and_linked_visits** function to remove the **passed patient** from the **passed graph**!. \n",
    "    - This function return a new graph with the needed patients and connecting medical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    final_HG = HG_inst.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    final_HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "# =================================================================================\n",
    "\n",
    "# We create new HG instance for the new (partial) network\n",
    "HG_obj = heterogeneous_Graph(final_HG)\n",
    "gHG.G_statistics(HG_obj.HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import XY_preparation as XY\n",
    "# ============================ Extracting Patient-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "# ============================ Extracting Visit-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "XV = XY_inst.X_visit\n",
    "YV = XY_inst.Y_visit\n",
    "# ==================================== Saving X and Y  (patient-based) ============================\n",
    "torch.save(X, f'{base_path}/OHV/X.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/Y.pt')\n",
    "# ==================================== Saving X and Y (visit-based) =================================\n",
    "torch.save(X, f'{base_path}/OHV/XV.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/YV.pt')\n",
    "del X\n",
    "del Y\n",
    "del XV\n",
    "del YV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-path Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import meta_path_2 as MP\n",
    "# ======================= Computing the Meta Path based Similarities ======================\n",
    "MP_inst = MP.Meta_path(final_HG, similarity_type = 'PC', saving_path = saving_path)\n",
    "# ==================================== SAVING =============================================\n",
    "nx.write_gml(final_HG, f'{base_path}/GMLs/HG.gml')\n",
    "save_list_as_pickle(MP_inst.Nodes,   f'{base_path}/GMLs', 'Nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to PSGs/\n",
    "\n",
    "from module1 import patients_sim as PS   \n",
    "\n",
    "HG_obj2 = heterogeneous_Graph(final_HG)\n",
    "\n",
    "PS.Patients_Similarity(HG_obj2.HG, HG_obj2.Nodes, base_path)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import reduction as Red\n",
    "Red.Reduction(base_path, PSGs=PSGs_ing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
