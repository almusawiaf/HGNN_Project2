{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "1. Generate the Heterogeneous graph\n",
    "2. Generate the feature set and labels.\n",
    "3. Generate the k-metapath-based similarity matrices\n",
    "4. Reduce and Convert the As to edge-list based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    import pickle\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G\n",
    "        Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in Nodes if v[0]=='C']\n",
    "        self.Visits =      [v for v in Nodes if v[0]=='V']\n",
    "        self.Medications = [v for v in Nodes if v[0]=='M']\n",
    "        self.Diagnoses  =  [v for v in Nodes if v[0]=='D']\n",
    "        self.Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "        self.Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "        self.MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "        self.Nodes = self.Patients  + self.Visits + self.Medications + self.Diagnoses + self.Procedures + self.Labs + self.MicroBio\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 DMPLB2 PC 1500 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path', '../../MIMIC_resources')\n",
    "\n",
    "disease_data_path = os.getenv('disease_data_path', '../Data')\n",
    "\n",
    "num_Diseases    = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE    = os.getenv('DISEASE_FILE', f'DMPLB2')  \n",
    "similarity_type = os.getenv('similarity_type', 'PC')  # options are PC: PathCount, SPS: Symmetric PathSim\n",
    "\n",
    "num_Sample      = int(os.getenv('num_Sample', 1500))  \n",
    "r_u_sampling    = os.getenv('r_u_sampling', 'True')  \n",
    "PSGs_ing        = os.getenv('PSGs_ing', 'True')  \n",
    "\n",
    "\n",
    "if r_u_sampling=='True':\n",
    "    sampling = True\n",
    "else:\n",
    "    sampling = False\n",
    "\n",
    "if PSGs_ing=='True':\n",
    "    PSGs_ing = True\n",
    "else:\n",
    "    PSGs_ing = False\n",
    "\n",
    "print(num_Diseases, DISEASE_FILE, similarity_type, num_Sample, sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/203_Diagnoses/DMPLB2/1500/HGNN_data\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "base_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs', 'SNFs']:\n",
    "    os.makedirs(f'{base_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{base_path}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "os.makedirs(f'{saving_path}/edges', exist_ok=True)\n",
    "# =================================================================================\n",
    "print(saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating complete HG from scratch\n",
    "- HG_inst: is an object that holds the heterogeneous graph information such as the graph (HG), Nodes, separated lists for the different types of nodes (Patients, visits, diagnoses, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46517\n",
      "Number of Visits = 58929\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "Number of Lab tests  = 993\n",
      "Number of MicroBio   = 65\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Extracting bipartite networks...\n",
      "\n",
      "Extracting and adding data of Visits\n",
      "\n",
      "Extracting and adding data of Diagnosis\n",
      "\n",
      "Extracting and adding data of Procedures\n",
      "\n",
      "Extracting and adding data of Medications\n",
      "\n",
      "Extracting and adding data of Lab tests\n",
      "\n",
      "Extracting and adding data of MicroBiology tests\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 993\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5360286\n",
      "------------------------------------------\n",
      "\n",
      "Removing isolated nodes\n",
      "Number of PATIENTS to remove: 0\n",
      "Number of nodes to remove: 0\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from module1 import generating_HG as gHG\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "gHG.G_statistics(HG_inst.HG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole graph / Sample graph / Selected Patients only?\n",
    "\n",
    "- Do we want to work on the entire graph or a sample of graph?\n",
    "- We can create our own graph accordingly, for example: \n",
    "    - Identifying specific set of patients to keep\n",
    "    - Identifying the rest of patients to remove,\n",
    "    - call the  **remove_patients_and_linked_visits** function to remove the **passed patient** from the **passed graph**!. \n",
    "    - This function return a new graph with the needed patients and connecting medical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44937 1500 46437\n",
      "Number of PATIENTS to remove: 44937\n",
      "Number of nodes to remove: 101802\n",
      "number of patients = 1500\n",
      "number of visits = 2064\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 187796\n",
      "------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    final_HG = HG_inst.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    final_HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "# =================================================================================\n",
    "\n",
    "# We create new HG instance for the new (partial) network\n",
    "HG_obj = heterogeneous_Graph(final_HG)\n",
    "gHG.G_statistics(HG_obj.HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting the feature set for all nodes\n",
      "getting the feature set for all nodes: visit_level\n",
      "getting the feature set for all nodes\n",
      "getting the feature set for all nodes: visit_level\n"
     ]
    }
   ],
   "source": [
    "from module1 import XY_preparation as XY\n",
    "# ============================ Extracting Patient-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "# ============================ Extracting Visit-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "XV = XY_inst.X_visit\n",
    "YV = XY_inst.Y_visit\n",
    "# ==================================== Saving X and Y  (patient-based) ============================\n",
    "torch.save(X, f'{base_path}/OHV/X.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/Y.pt')\n",
    "# ==================================== Saving X and Y (visit-based) =================================\n",
    "torch.save(X, f'{base_path}/OHV/XV.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/YV.pt')\n",
    "del X\n",
    "del Y\n",
    "del XV\n",
    "del YV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-path Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting As from HG\n",
      "\n",
      "=============================================================\n",
      "Patients:\n",
      "\tWorking on: Patient-Medication\n",
      "\tWorking on: Patient-Diagnosis\n",
      "\tWorking on: Patient-Procedure\n",
      "\tWorking on: Patient-Lab\n",
      "\tWorking on: Patient-MicroBiology\n",
      "Diagnoses:\n",
      "\tWorking on: Diagnosis-Medication\n",
      "\tWorking on: Diagnosis-Procedure\n",
      "\tWorking on: Diagnosis-Lab\n",
      "\tWorking on: Diagnosis-MicroBiology\n",
      "Procedures:\n",
      "\tWorking on: Procedure-Medication\n",
      "\tWorking on: Procedure-Lab\n",
      "\tWorking on: Procedure-MicroBiology\n",
      "\tWorking on: Medication-Lab\n",
      "\tWorking on: Medication-MicroBiology\n",
      "\tWorking on: Lab-MicroBiology\n",
      "Homogeneous similarity\n",
      "1. Patient-Patient\n",
      "\tWorking on: Patient-Visit-Medication-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Diagnosis-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Procedure-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Lab-Visit-Patient\n",
      "\tWorking on: Patient-Visit-MicroBiology-Visit-Patient\n",
      "2. visit-visit\n",
      "\tWorking on: Visit-Medication-Visit\n",
      "\tWorking on: Visit-Diagnosis-Visit\n",
      "\tWorking on: Visit-Procedure-Visit\n",
      "\tWorking on: Visit-Lab-Visit\n",
      "\tWorking on: Visit-MicroBiology-Visit\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/1500/HGNN_data/As/selected_i.pkl\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/1500/GMLs/Nodes.pkl\n"
     ]
    }
   ],
   "source": [
    "from module1 import meta_path_2 as MP\n",
    "# ======================= Computing the Meta Path based Similarities ======================\n",
    "MP_inst = MP.Meta_path(final_HG, similarity_type = 'PC', saving_path = saving_path)\n",
    "# ==================================== SAVING =============================================\n",
    "nx.write_gml(final_HG, f'{base_path}/GMLs/HG.gml')\n",
    "save_list_as_pickle(MP_inst.Nodes,   f'{base_path}/GMLs', 'Nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure the similarity, expand it and save to PSGs/M.npz\n",
      "Getting the OHV for M\n",
      "Measure the similarity, expand it and save to PSGs/D.npz\n",
      "Getting the OHV for D\n",
      "Measure the similarity, expand it and save to PSGs/P.npz\n",
      "Getting the OHV for P\n",
      "Measure the similarity, expand it and save to PSGs/L.npz\n",
      "Getting the OHV for L\n",
      "Measure the similarity, expand it and save to PSGs/B.npz\n",
      "Getting the OHV for B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module1.patients_sim.Patients_Similarity at 0x7f47ebc69a90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the data to PSGs/\n",
    "\n",
    "from module1 import patients_sim as PS   \n",
    "\n",
    "HG_obj2 = heterogeneous_Graph(final_HG)\n",
    "\n",
    "PS.Patients_Similarity(HG_obj2.HG, HG_obj2.Nodes, base_path)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Matrix 0: 1939 non-zero elements\n",
      "\tSaving all non-zero values... (1939 non-zero elements)\n",
      "Matrix 1: 407 non-zero elements\n",
      "\tSaving all non-zero values... (407 non-zero elements)\n",
      "Matrix 2: 18143 non-zero elements\n",
      "\tSaving all non-zero values... (18143 non-zero elements)\n",
      "Matrix 3: 5928 non-zero elements\n",
      "\tSaving all non-zero values... (5928 non-zero elements)\n",
      "Matrix 4: 160076 non-zero elements\n",
      "\tSaving all non-zero values... (160076 non-zero elements)\n",
      "Matrix 5: 1303 non-zero elements\n",
      "\tSaving all non-zero values... (1303 non-zero elements)\n",
      "Matrix 6: 356 non-zero elements\n",
      "\tSaving all non-zero values... (356 non-zero elements)\n",
      "Matrix 7: 15548 non-zero elements\n",
      "\tSaving all non-zero values... (15548 non-zero elements)\n",
      "Matrix 8: 5213 non-zero elements\n",
      "\tSaving all non-zero values... (5213 non-zero elements)\n",
      "Matrix 9: 127992 non-zero elements\n",
      "\tSaving all non-zero values... (127992 non-zero elements)\n",
      "Matrix 10: 1161 non-zero elements\n",
      "\tSaving all non-zero values... (1161 non-zero elements)\n",
      "Matrix 11: 3685 non-zero elements\n",
      "\tSaving all non-zero values... (3685 non-zero elements)\n",
      "Matrix 12: 7125 non-zero elements\n",
      "\tSaving all non-zero values... (7125 non-zero elements)\n",
      "Matrix 13: 68100 non-zero elements\n",
      "\tSaving all non-zero values... (68100 non-zero elements)\n",
      "Matrix 14: 2459 non-zero elements\n",
      "\tSaving all non-zero values... (2459 non-zero elements)\n",
      "Matrix 15: 755 non-zero elements\n",
      "\tSaving all non-zero values... (755 non-zero elements)\n",
      "Matrix 16: 22358 non-zero elements\n",
      "\tSaving all non-zero values... (22358 non-zero elements)\n",
      "Matrix 17: 838 non-zero elements\n",
      "\tSaving all non-zero values... (838 non-zero elements)\n",
      "Matrix 18: 23492 non-zero elements\n",
      "\tSaving all non-zero values... (23492 non-zero elements)\n",
      "Matrix 19: 151 non-zero elements\n",
      "\tSaving all non-zero values... (151 non-zero elements)\n",
      "Matrix 20: 0 non-zero elements\n",
      "Matrix 20 has zero values. Not saving...\n",
      "Matrix 21: 28 non-zero elements\n",
      "\tSaving all non-zero values... (28 non-zero elements)\n",
      "Matrix 22: 582908 non-zero elements\n",
      "\tSaving all non-zero values... (582908 non-zero elements)\n",
      "Matrix 23: 511665 non-zero elements\n",
      "\tSaving all non-zero values... (511665 non-zero elements)\n",
      "Matrix 24: 1098389 non-zero elements\n",
      "\tSaving one million non-zero values... (after reduction: 1000000 non-zero elements)\n",
      "Matrix 25: 81416 non-zero elements\n",
      "\tSaving all non-zero values... (81416 non-zero elements)\n",
      "Matrix 26: 5816 non-zero elements\n",
      "\tSaving all non-zero values... (5816 non-zero elements)\n",
      "Matrix 27: 997963 non-zero elements\n",
      "\tSaving all non-zero values... (997963 non-zero elements)\n",
      "Matrix 28: 748121 non-zero elements\n",
      "\tSaving all non-zero values... (748121 non-zero elements)\n",
      "Matrix 29: 2125768 non-zero elements\n",
      "\tSaving one million non-zero values... (after reduction: 1000000 non-zero elements)\n",
      "Matrix 30: 117382 non-zero elements\n",
      "\tSaving all non-zero values... (117382 non-zero elements)\n",
      "Matrix 31: 81416 non-zero elements\n",
      "\tSaving all non-zero values... (81416 non-zero elements)\n",
      "Matrix 32: 582908 non-zero elements\n",
      "\tSaving all non-zero values... (582908 non-zero elements)\n",
      "Matrix 33: 1098389 non-zero elements\n",
      "\tSaving one million non-zero values... (after reduction: 1000000 non-zero elements)\n",
      "Matrix 34: 28 non-zero elements\n",
      "\tSaving all non-zero values... (28 non-zero elements)\n",
      "Matrix 35: 511665 non-zero elements\n",
      "\tSaving all non-zero values... (511665 non-zero elements)\n",
      "done saving [unique edges]:  3673228\n",
      "Working on 0th file...\n",
      "Working on 1th file...\n",
      "Working on 2th file...\n",
      "Working on 3th file...\n",
      "Working on 4th file...\n",
      "Working on 5th file...\n",
      "Working on 6th file...\n",
      "Working on 7th file...\n",
      "Working on 8th file...\n",
      "Working on 9th file...\n",
      "Working on 10th file...\n",
      "Working on 11th file...\n",
      "Working on 12th file...\n",
      "Working on 13th file...\n",
      "Working on 14th file...\n",
      "Working on 15th file...\n",
      "Working on 16th file...\n",
      "Working on 17th file...\n",
      "Working on 18th file...\n",
      "Working on 19th file...\n",
      "Working on 20th file...\n",
      "Working on 21th file...\n",
      "Working on 22th file...\n",
      "Working on 23th file...\n",
      "Working on 24th file...\n",
      "Working on 25th file...\n",
      "Working on 26th file...\n",
      "Working on 27th file...\n",
      "Working on 28th file...\n",
      "Working on 29th file...\n",
      "Working on 30th file...\n",
      "Working on 31th file...\n",
      "Working on 32th file...\n",
      "Working on 33th file...\n",
      "Working on 34th file...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module1.reduction.Reduction at 0x7f47a26c9bd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from module1 import reduction as Red\n",
    "Red.Reduction(base_path, PSGs=PSGs_ing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
