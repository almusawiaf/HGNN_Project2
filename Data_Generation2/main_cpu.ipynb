{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "1. Generate the Heterogeneous graph\n",
    "2. Generate the feature set from the clinical notes.\n",
    "3. Generate the Labels\n",
    "4. Generate the k-metapath-based similarity matrices\n",
    "5. Convert the As to edge-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    import pickle\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G\n",
    "        Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in Nodes if v[0]=='C']\n",
    "        self.Visits =      [v for v in Nodes if v[0]=='V']\n",
    "        self.Medications = [v for v in Nodes if v[0]=='M']\n",
    "        self.Diagnoses  =  [v for v in Nodes if v[0]=='D']\n",
    "        self.Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "        self.Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "        self.MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "        self.Nodes = self.Patients  + self.Visits + self.Medications + self.Diagnoses + self.Procedures + self.Labs + self.MicroBio\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 DMPLB2 PC 250 True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # OAK :-)\n",
    "# MIMIC_Path        = os.getenv('MIMIC_Path',        '/home/almusawiaf/MyDocuments/PhD_Projects/Data/MIMIC_resources')\n",
    "\n",
    "# Check for Athena :-(\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path', '../../MIMIC_resources')\n",
    "\n",
    "disease_data_path = os.getenv('disease_data_path', '../Data')\n",
    "\n",
    "num_Diseases    = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE    = os.getenv('DISEASE_FILE', f'DMPLB2')  \n",
    "similarity_type = os.getenv('similarity_type', 'PC')  # options are PC: PathCount, SPS: Symmetric PathSim\n",
    "\n",
    "num_Sample      = int(os.getenv('num_Sample', 250))  \n",
    "r_u_sampling    = os.getenv('r_u_sampling', 'True')  \n",
    "PSGs_ing        = os.getenv('PSGs_ing', 'False')  \n",
    "\n",
    "\n",
    "if r_u_sampling=='True':\n",
    "    sampling = True\n",
    "else:\n",
    "    sampling = False\n",
    "\n",
    "if PSGs_ing=='True':\n",
    "    PSGs_ing = True\n",
    "else:\n",
    "    PSGs_ing = False\n",
    "\n",
    "print(num_Diseases, DISEASE_FILE, similarity_type, num_Sample, sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/203_Diagnoses/DMPLB2/250/HGNN_data\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "base_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs', 'SNFs']:\n",
    "    os.makedirs(f'{base_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{base_path}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "os.makedirs(f'{saving_path}/edges', exist_ok=True)\n",
    "# =================================================================================\n",
    "\n",
    "# complete_HG = nx.read_gml(f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "print(saving_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating complete HG from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lustre/home/almusawiaf/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46517\n",
      "Number of Visits = 58929\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "Number of Lab tests  = 993\n",
      "Number of MicroBio   = 65\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Extracting bipartite networks...\n",
      "\n",
      "Extracting and adding data of Visits\n",
      "\n",
      "Extracting and adding data of Diagnosis\n",
      "\n",
      "Extracting and adding data of Procedures\n",
      "\n",
      "Extracting and adding data of Medications\n",
      "\n",
      "Extracting and adding data of Lab tests\n",
      "\n",
      "Extracting and adding data of MicroBiology tests\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 993\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5360286\n",
      "------------------------------------------\n",
      "\n",
      "Removing isolated nodes\n",
      "Number of PATIENTS to remove: 0\n",
      "Number of nodes to remove: 0\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "46187 250 46437\n",
      "Number of PATIENTS to remove: 46187\n",
      "Number of nodes to remove: 104664\n"
     ]
    }
   ],
   "source": [
    "from module1 import generating_HG as gHG\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "gHG.G_statistics(HG_inst.HG)\n",
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    HG = HG_inst.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "# =================================================================================\n",
    "complete_HG = HG_inst.HG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole graph or Sample graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of patients = 250\n",
      "number of visits = 452\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 35274\n",
      "------------------------------------------\n",
      "\n",
      "0 250 250\n",
      "Number of PATIENTS to remove: 0\n",
      "Number of nodes to remove: 0\n"
     ]
    }
   ],
   "source": [
    "# complete_HG = nx.read_gml(f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "HG_obj = heterogeneous_Graph(complete_HG)\n",
    "\n",
    "gHG.G_statistics(HG_obj.HG)\n",
    "\n",
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_obj.Patients)\n",
    "    HG = HG_obj.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_obj.Patients, len(HG_obj.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_obj.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_obj.HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting the feature set for all nodes\n",
      "getting the feature set for all nodes: visit_level\n",
      "getting the feature set for all nodes\n",
      "getting the feature set for all nodes: visit_level\n"
     ]
    }
   ],
   "source": [
    "from module1 import XY_preparation as XY\n",
    "# ============================ Extracting Patient-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "# ============================ Extracting Visit-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(HG)\n",
    "XV = XY_inst.X_visit\n",
    "YV = XY_inst.Y_visit\n",
    "# ==================================== Saving X and Y  (patient-based) ============================\n",
    "torch.save(X, f'{base_path}/OHV/X.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/Y.pt')\n",
    "# ==================================== Saving X and Y (visit-based) =================================\n",
    "torch.save(X, f'{base_path}/OHV/XV.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/YV.pt')\n",
    "del X\n",
    "del Y\n",
    "del XV\n",
    "del YV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-path Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting As from HG\n",
      "\n",
      "=============================================================\n",
      "Patients:\n",
      "\tWorking on: Patient-Medication\n",
      "\tWorking on: Patient-Diagnosis\n",
      "\tWorking on: Patient-Procedure\n",
      "\tWorking on: Patient-Lab\n",
      "\tWorking on: Patient-MicroBiology\n",
      "Diagnoses:\n",
      "\tWorking on: Diagnosis-Medication\n",
      "\tWorking on: Diagnosis-Procedure\n",
      "\tWorking on: Diagnosis-Lab\n",
      "\tWorking on: Diagnosis-MicroBiology\n",
      "Procedures:\n",
      "\tWorking on: Procedure-Medication\n",
      "\tWorking on: Procedure-Lab\n",
      "\tWorking on: Procedure-MicroBiology\n",
      "\tWorking on: Medication-Lab\n",
      "\tWorking on: Medication-MicroBiology\n",
      "\tWorking on: Lab-MicroBiology\n",
      "Homogeneous similarity\n",
      "1. Patient-Patient\n",
      "\tWorking on: Patient-Visit-Medication-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Diagnosis-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Procedure-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Lab-Visit-Patient\n",
      "\tWorking on: Patient-Visit-MicroBiology-Visit-Patient\n",
      "2. visit-visit\n",
      "\tWorking on: Visit-Medication-Visit\n",
      "\tWorking on: Visit-Diagnosis-Visit\n",
      "\tWorking on: Visit-Procedure-Visit\n",
      "\tWorking on: Visit-Lab-Visit\n",
      "\tWorking on: Visit-MicroBiology-Visit\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/250/HGNN_data/As/selected_i.pkl\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/250/GMLs/Nodes.pkl\n"
     ]
    }
   ],
   "source": [
    "from module1 import meta_path_2 as MP\n",
    "# ======================= Computing the Meta Path based Similarities ======================\n",
    "MP_inst = MP.Meta_path(HG, similarity_type = 'PC', saving_path = saving_path)\n",
    "# ==================================== SAVING =============================================\n",
    "nx.write_gml(HG, f'{base_path}/GMLs/HG.gml')\n",
    "save_list_as_pickle(MP_inst.Nodes,   f'{base_path}/GMLs', 'Nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measure the similarity, expand it and save to PSGs/M.npz\n",
      "Getting the OHV for M\n",
      "Measure the similarity, expand it and save to PSGs/D.npz\n",
      "Getting the OHV for D\n",
      "Measure the similarity, expand it and save to PSGs/P.npz\n",
      "Getting the OHV for P\n",
      "Measure the similarity, expand it and save to PSGs/L.npz\n",
      "Getting the OHV for L\n",
      "Measure the similarity, expand it and save to PSGs/B.npz\n",
      "Getting the OHV for B\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Patients_Similarity at 0x7f216478d360>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the data to PSGs/\n",
    "\n",
    "from module1 import patients_sim as PS   \n",
    "\n",
    "HG_obj2 = heterogeneous_Graph(HG)\n",
    "\n",
    "PS.Patients_Similarity(HG_obj2.HG, HG_obj2.Nodes, base_path)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Matrix 0: 327 non-zero elements\n",
      "\tSaving all non-zero values... (327 non-zero elements)\n",
      "Matrix 1: 607 non-zero elements\n",
      "\tSaving all non-zero values... (607 non-zero elements)\n",
      "Matrix 2: 3044 non-zero elements\n",
      "\tSaving all non-zero values... (3044 non-zero elements)\n",
      "Matrix 3: 1097 non-zero elements\n",
      "\tSaving all non-zero values... (1097 non-zero elements)\n",
      "Matrix 4: 29989 non-zero elements\n",
      "\tSaving all non-zero values... (29989 non-zero elements)\n",
      "Matrix 5: 210 non-zero elements\n",
      "\tSaving all non-zero values... (210 non-zero elements)\n",
      "Matrix 6: 141 non-zero elements\n",
      "\tSaving all non-zero values... (141 non-zero elements)\n",
      "Matrix 7: 2433 non-zero elements\n",
      "\tSaving all non-zero values... (2433 non-zero elements)\n",
      "Matrix 8: 817 non-zero elements\n",
      "\tSaving all non-zero values... (817 non-zero elements)\n",
      "Matrix 9: 19757 non-zero elements\n",
      "\tSaving all non-zero values... (19757 non-zero elements)\n",
      "Matrix 10: 158 non-zero elements\n",
      "\tSaving all non-zero values... (158 non-zero elements)\n",
      "Matrix 11: 3713 non-zero elements\n",
      "\tSaving all non-zero values... (3713 non-zero elements)\n",
      "Matrix 12: 3376 non-zero elements\n",
      "\tSaving all non-zero values... (3376 non-zero elements)\n",
      "Matrix 13: 41723 non-zero elements\n",
      "\tSaving all non-zero values... (41723 non-zero elements)\n",
      "Matrix 14: 1040 non-zero elements\n",
      "\tSaving all non-zero values... (1040 non-zero elements)\n",
      "Matrix 15: 874 non-zero elements\n",
      "\tSaving all non-zero values... (874 non-zero elements)\n",
      "Matrix 16: 13422 non-zero elements\n",
      "\tSaving all non-zero values... (13422 non-zero elements)\n",
      "Matrix 17: 324 non-zero elements\n",
      "\tSaving all non-zero values... (324 non-zero elements)\n",
      "Matrix 18: 17497 non-zero elements\n",
      "\tSaving all non-zero values... (17497 non-zero elements)\n",
      "Matrix 19: 457 non-zero elements\n",
      "\tSaving all non-zero values... (457 non-zero elements)\n",
      "Matrix 20: 0 non-zero elements\n",
      "Matrix 20 has zero values. Not saving...\n",
      "Matrix 21: 0 non-zero elements\n",
      "Matrix 21 has zero values. Not saving...\n",
      "Matrix 22: 15251 non-zero elements\n",
      "\tSaving all non-zero values... (15251 non-zero elements)\n",
      "Matrix 23: 12872 non-zero elements\n",
      "\tSaving all non-zero values... (12872 non-zero elements)\n",
      "Matrix 24: 29493 non-zero elements\n",
      "\tSaving all non-zero values... (29493 non-zero elements)\n",
      "Matrix 25: 1349 non-zero elements\n",
      "\tSaving all non-zero values... (1349 non-zero elements)\n",
      "Matrix 26: 5567 non-zero elements\n",
      "\tSaving all non-zero values... (5567 non-zero elements)\n",
      "Matrix 27: 34043 non-zero elements\n",
      "\tSaving all non-zero values... (34043 non-zero elements)\n",
      "Matrix 28: 24551 non-zero elements\n",
      "\tSaving all non-zero values... (24551 non-zero elements)\n",
      "Matrix 29: 156751 non-zero elements\n",
      "\tSaving all non-zero values... (156751 non-zero elements)\n",
      "Matrix 30: 2898 non-zero elements\n",
      "\tSaving all non-zero values... (2898 non-zero elements)\n",
      "Matrix 31: 1349 non-zero elements\n",
      "\tSaving all non-zero values... (1349 non-zero elements)\n",
      "Matrix 32: 15251 non-zero elements\n",
      "\tSaving all non-zero values... (15251 non-zero elements)\n",
      "Matrix 33: 29493 non-zero elements\n",
      "\tSaving all non-zero values... (29493 non-zero elements)\n",
      "Matrix 34: 0 non-zero elements\n",
      "Matrix 34 has zero values. Not saving...\n",
      "Matrix 35: 12872 non-zero elements\n",
      "\tSaving all non-zero values... (12872 non-zero elements)\n",
      "done saving [unique edges]:  356684\n",
      "Working on 0th file...\n",
      "Working on 1th file...\n",
      "Working on 2th file...\n",
      "Working on 3th file...\n",
      "Working on 4th file...\n",
      "Working on 5th file...\n",
      "Working on 6th file...\n",
      "Working on 7th file...\n",
      "Working on 8th file...\n",
      "Working on 9th file...\n",
      "Working on 10th file...\n",
      "Working on 11th file...\n",
      "Working on 12th file...\n",
      "Working on 13th file...\n",
      "Working on 14th file...\n",
      "Working on 15th file...\n",
      "Working on 16th file...\n",
      "Working on 17th file...\n",
      "Working on 18th file...\n",
      "Working on 19th file...\n",
      "Working on 20th file...\n",
      "Working on 21th file...\n",
      "Working on 22th file...\n",
      "Working on 23th file...\n",
      "Working on 24th file...\n",
      "Working on 25th file...\n",
      "Working on 26th file...\n",
      "Working on 27th file...\n",
      "Working on 28th file...\n",
      "Working on 29th file...\n",
      "Working on 30th file...\n",
      "Working on 31th file...\n",
      "Working on 32th file...\n"
     ]
    }
   ],
   "source": [
    "from module1 import reduction as Red\n",
    "Red.Reduction(base_path, PSGs=PSGs_ing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
