{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of diseases (labels) = 203\n",
      "Disease File = DMPLB2\n",
      "similarity_type = PC\n",
      "num_Sample = 500\n",
      "sampling = True\n",
      "../Data/203_Diagnoses/DMPLB2/500/HGNN_data\n",
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n",
      "General Information:\n",
      "---------------------------\n",
      "Number of Patients = 46517\n",
      "Number of Visits = 58929\n",
      "Number of Diagnosis = 203\n",
      "Number of procedures = 89\n",
      "Number of Medication = 592\n",
      "Number of Lab tests  = 993\n",
      "Number of MicroBio   = 65\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Extracting bipartite networks...\n",
      "\n",
      "Extracting and adding data of Visits\n",
      "\n",
      "Extracting and adding data of Diagnosis\n",
      "\n",
      "Extracting and adding data of Procedures\n",
      "\n",
      "Extracting and adding data of Medications\n",
      "\n",
      "Extracting and adding data of Lab tests\n",
      "\n",
      "Extracting and adding data of MicroBiology tests\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 993\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5360286\n",
      "------------------------------------------\n",
      "\n",
      "Removing isolated nodes\n",
      "Number of PATIENTS to remove: 0\n",
      "Number of nodes to remove: 0\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "number of patients = 46437\n",
      "number of visits = 58929\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 5336561\n",
      "------------------------------------------\n",
      "\n",
      "45937 500 46437\n",
      "Number of PATIENTS to remove: 45937\n",
      "Number of nodes to remove: 104084\n",
      "number of patients = 500\n",
      "number of visits = 782\n",
      "number of Medication = 592\n",
      "number of Diagnoses = 203\n",
      "number of Procedures = 89\n",
      "number of Labs = 480\n",
      "number of MicoBio = 64\n",
      "number of Edges = 64929\n",
      "------------------------------------------\n",
      "\n",
      "Number of rows with zero sum: 8\n",
      "Number of PATIENTS to remove: 8\n",
      "Number of nodes to remove: 40\n",
      "getting the feature set for all nodes\n",
      "Create a new One Hot vector per node\n",
      "extracting As from HG\n",
      "\n",
      "=============================================================\n",
      "Patients:\n",
      "\tWorking on: Patient-Medication\n",
      "\tWorking on: Patient-Diagnosis\n",
      "\tWorking on: Patient-Procedure\n",
      "\tWorking on: Patient-Lab\n",
      "\tWorking on: Patient-MicroBiology\n",
      "Diagnoses:\n",
      "\tWorking on: Diagnosis-Medication\n",
      "\tWorking on: Diagnosis-Procedure\n",
      "\tWorking on: Diagnosis-Lab\n",
      "\tWorking on: Diagnosis-MicroBiology\n",
      "Procedures:\n",
      "\tWorking on: Procedure-Medication\n",
      "\tWorking on: Procedure-Lab\n",
      "\tWorking on: Procedure-MicroBiology\n",
      "\tWorking on: Medication-Lab\n",
      "\tWorking on: Medication-MicroBiology\n",
      "\tWorking on: Lab-MicroBiology\n",
      "Homogeneous similarity\n",
      "1. Patient-Patient\n",
      "\tWorking on: Patient-Visit-Medication-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Diagnosis-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Procedure-Visit-Patient\n",
      "\tWorking on: Patient-Visit-Lab-Visit-Patient\n",
      "\tWorking on: Patient-Visit-MicroBiology-Visit-Patient\n",
      "2. visit-visit\n",
      "\tWorking on: Visit-Medication-Visit\n",
      "\tWorking on: Visit-Diagnosis-Visit\n",
      "\tWorking on: Visit-Procedure-Visit\n",
      "\tWorking on: Visit-Lab-Visit\n",
      "\tWorking on: Visit-MicroBiology-Visit\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/HGNN_data/As/selected_i.pkl\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/HGNN_data/As/metapath_list.pkl\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/GMLs/Nodes.pkl\n",
      "Measure the similarity, expand it and save to PSGs/M.npz\n",
      "Getting the OHV for M\n",
      "Measure the similarity, expand it and save to PSGs/D.npz\n",
      "Getting the OHV for D\n",
      "Measure the similarity, expand it and save to PSGs/P.npz\n",
      "Getting the OHV for P\n",
      "Measure the similarity, expand it and save to PSGs/L.npz\n",
      "Getting the OHV for L\n",
      "Measure the similarity, expand it and save to PSGs/B.npz\n",
      "Getting the OHV for B\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/PSGs/PSGs_List.pkl\n",
      "30\n",
      "Matrix 0: 625 non-zero elements\n",
      "\tSaving all non-zero values... (625 non-zero elements)\n",
      "Matrix 1: 49 non-zero elements\n",
      "\tSaving all non-zero values... (49 non-zero elements)\n",
      "Matrix 2: 5698 non-zero elements\n",
      "\tSaving all non-zero values... (5698 non-zero elements)\n",
      "Matrix 3: 1972 non-zero elements\n",
      "\tSaving all non-zero values... (1972 non-zero elements)\n",
      "Matrix 4: 53691 non-zero elements\n",
      "\tSaving all non-zero values... (53691 non-zero elements)\n",
      "Matrix 5: 380 non-zero elements\n",
      "\tSaving all non-zero values... (380 non-zero elements)\n",
      "Matrix 6: 49 non-zero elements\n",
      "\tSaving all non-zero values... (49 non-zero elements)\n",
      "Matrix 7: 4855 non-zero elements\n",
      "\tSaving all non-zero values... (4855 non-zero elements)\n",
      "Matrix 8: 1638 non-zero elements\n",
      "\tSaving all non-zero values... (1638 non-zero elements)\n",
      "Matrix 9: 40381 non-zero elements\n",
      "\tSaving all non-zero values... (40381 non-zero elements)\n",
      "Matrix 10: 337 non-zero elements\n",
      "\tSaving all non-zero values... (337 non-zero elements)\n",
      "Matrix 11: 659 non-zero elements\n",
      "\tSaving all non-zero values... (659 non-zero elements)\n",
      "Matrix 12: 4483 non-zero elements\n",
      "\tSaving all non-zero values... (4483 non-zero elements)\n",
      "Matrix 13: 51443 non-zero elements\n",
      "\tSaving all non-zero values... (51443 non-zero elements)\n",
      "Matrix 14: 1380 non-zero elements\n",
      "\tSaving all non-zero values... (1380 non-zero elements)\n",
      "Matrix 15: 22 non-zero elements\n",
      "\tSaving all non-zero values... (22 non-zero elements)\n",
      "Matrix 16: 16394 non-zero elements\n",
      "\tSaving all non-zero values... (16394 non-zero elements)\n",
      "Matrix 17: 422 non-zero elements\n",
      "\tSaving all non-zero values... (422 non-zero elements)\n",
      "Matrix 18: 3704 non-zero elements\n",
      "\tSaving all non-zero values... (3704 non-zero elements)\n",
      "Matrix 19: 22 non-zero elements\n",
      "\tSaving all non-zero values... (22 non-zero elements)\n",
      "Matrix 20: 0 non-zero elements\n",
      "Matrix 20 has zero values. Not saving...\n",
      "Matrix 21: 1 non-zero elements\n",
      "\tSaving all non-zero values... (1 non-zero elements)\n",
      "Matrix 22: 58503 non-zero elements\n",
      "\tSaving all non-zero values... (58503 non-zero elements)\n",
      "Matrix 23: 46913 non-zero elements\n",
      "\tSaving all non-zero values... (46913 non-zero elements)\n",
      "Matrix 24: 117307 non-zero elements\n",
      "\tSaving all non-zero values... (117307 non-zero elements)\n",
      "Matrix 25: 6757 non-zero elements\n",
      "\tSaving all non-zero values... (6757 non-zero elements)\n",
      "Matrix 26: 580 non-zero elements\n",
      "\tSaving all non-zero values... (580 non-zero elements)\n",
      "Matrix 27: 107976 non-zero elements\n",
      "\tSaving all non-zero values... (107976 non-zero elements)\n",
      "Matrix 28: 74408 non-zero elements\n",
      "\tSaving all non-zero values... (74408 non-zero elements)\n",
      "Matrix 29: 340991 non-zero elements\n",
      "\tSaving all non-zero values... (340991 non-zero elements)\n",
      "Matrix 30: 9020 non-zero elements\n",
      "\tSaving all non-zero values... (9020 non-zero elements)\n",
      "Matrix 31: 6757 non-zero elements\n",
      "\tSaving all non-zero values... (6757 non-zero elements)\n",
      "Matrix 32: 58503 non-zero elements\n",
      "\tSaving all non-zero values... (58503 non-zero elements)\n",
      "Matrix 33: 117307 non-zero elements\n",
      "\tSaving all non-zero values... (117307 non-zero elements)\n",
      "Matrix 34: 1 non-zero elements\n",
      "\tSaving all non-zero values... (1 non-zero elements)\n",
      "Matrix 35: 46913 non-zero elements\n",
      "\tSaving all non-zero values... (46913 non-zero elements)\n",
      "done saving [unique edges]:  721344\n",
      "Working on 0th file...\n",
      "Working on 1th file...\n",
      "Working on 2th file...\n",
      "Working on 3th file...\n",
      "Working on 4th file...\n",
      "Working on 5th file...\n",
      "Working on 6th file...\n",
      "Working on 7th file...\n",
      "Working on 8th file...\n",
      "Working on 9th file...\n",
      "Working on 10th file...\n",
      "Working on 11th file...\n",
      "Working on 12th file...\n",
      "Working on 13th file...\n",
      "Working on 14th file...\n",
      "Working on 15th file...\n",
      "Working on 16th file...\n",
      "Working on 17th file...\n",
      "Working on 18th file...\n",
      "Working on 19th file...\n",
      "Working on 20th file...\n",
      "Working on 21th file...\n",
      "Working on 22th file...\n",
      "Working on 23th file...\n",
      "Working on 24th file...\n",
      "Working on 25th file...\n",
      "Working on 26th file...\n",
      "Working on 27th file...\n",
      "Working on 28th file...\n",
      "Working on 29th file...\n",
      "Working on 30th file...\n",
      "Working on 31th file...\n",
      "Working on 32th file...\n",
      "Working on 33th file...\n",
      "Working on 34th file...\n",
      "saving to ../Data/203_Diagnoses/DMPLB2/500/HGNN_data//edges/selected_meta_paths.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module1.reduction.Reduction at 0x7fa651732890>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Function to save a list as a pickle file\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n",
    "\n",
    "def load_dict_from_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_dict = pickle.load(file)\n",
    "    return loaded_dict  \n",
    "\n",
    "# Class representing a heterogeneous graph\n",
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G        \n",
    "        HG_Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in HG_Nodes if v[0] == 'C']\n",
    "        self.Visits =      [v for v in HG_Nodes if v[0] == 'V']\n",
    "        self.Medications = [v for v in HG_Nodes if v[0] == 'M']\n",
    "        self.Diagnosis  =  [v for v in HG_Nodes if v[0] == 'D']\n",
    "        self.Procedures =  [v for v in HG_Nodes if v[0] == 'P']\n",
    "        self.Labs       =  [v for v in HG_Nodes if v[0] == 'L']\n",
    "        self.MicroBio   =  [v for v in HG_Nodes if v[0] == 'B']\n",
    "        self.Nodes = self.Patients + self.Visits + self.Medications + self.Diagnosis + self.Procedures + self.Labs + self.MicroBio\n",
    "\n",
    "# Example code snippet using environment variables\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path', '../../MIMIC_resources')\n",
    "disease_data_path = os.getenv('disease_data_path', '../Data')\n",
    "num_Diseases      = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE      = os.getenv('DISEASE_FILE', 'DMPLB2')  \n",
    "similarity_type   = os.getenv('similarity_type', 'PC')  # options: PC, SPS\n",
    "num_Sample        = int(os.getenv('num_Sample', 500))  \n",
    "r_u_sampling      = os.getenv('r_u_sampling', 'True')  \n",
    "PSGs_ing          = os.getenv('PSGs_ing', 'True')\n",
    "\n",
    "# Convert string flags to boolean\n",
    "sampling = r_u_sampling == 'True'\n",
    "PSGs_ing = PSGs_ing == 'True'\n",
    "\n",
    "# Print the settings\n",
    "print(f'number of diseases (labels) = {num_Diseases}\\nDisease File = {DISEASE_FILE}\\nsimilarity_type = {similarity_type}\\nnum_Sample = {num_Sample}\\nsampling = {sampling}')\n",
    "\n",
    "# Define the base path for saving data\n",
    "base_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "# Create necessary directories\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs']:\n",
    "    os.makedirs(f'{base_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{base_path}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "os.makedirs(f'{saving_path}/edges', exist_ok=True)\n",
    "\n",
    "# Print the saving path\n",
    "print(saving_path)\n",
    "\n",
    "\n",
    "from module1 import generating_HG as gHG\n",
    "\n",
    "# Generating the heterogeneous graph (HG)\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "\n",
    "# Save the HG as a GML file\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "\n",
    "# Print the graph's statistics\n",
    "gHG.G_statistics(HG_inst.HG)\n",
    "# ===========================================================================================\n",
    "# Sampling or working with the whole graph\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    final_HG = HG_inst.HG\n",
    "else:\n",
    "    # Randomly sample patients to remove\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # Remove patients and linked visits\n",
    "    final_HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "\n",
    "# Create a new HG instance for the sampled graph\n",
    "HG_obj = heterogeneous_Graph(final_HG)\n",
    "\n",
    "# Print statistics for the new graph\n",
    "gHG.G_statistics(HG_obj.HG)\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import XY_preparation as XY\n",
    "\n",
    "# Extract patient-based X and Y\n",
    "XY_inst = XY.XY_preparation(final_HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "final_HG = XY_inst.HG\n",
    "\n",
    "# Save the feature set X and labels Y\n",
    "torch.save(X, f'{base_path}/OHV/X.pt')\n",
    "torch.save(Y, f'{base_path}/OHV/Y.pt')\n",
    "\n",
    "# Clean up memory\n",
    "del X\n",
    "del Y\n",
    "\n",
    "# Extract and save superclasses\n",
    "YY = XY_inst.get_Y_superclasses()\n",
    "torch.save(YY, f'{base_path}/OHV/Ysuperclass.pt')\n",
    "del YY\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import meta_path_2 as MP\n",
    "\n",
    "# Compute the meta-path-based similarities\n",
    "MP_inst = MP.Meta_path(final_HG, similarity_type='PC', saving_path=saving_path)\n",
    "\n",
    "# Save the heterogeneous graph in GML format\n",
    "nx.write_gml(final_HG, f'{base_path}/GMLs/HG.gml')\n",
    "\n",
    "# Save the nodes\n",
    "save_list_as_pickle(MP_inst.Nodes, f'{base_path}/GMLs', 'Nodes')\n",
    "\n",
    "# ===========================================================================================\n",
    "from module1 import patients_sim as PS   \n",
    "\n",
    "# Create a new heterogeneous graph instance\n",
    "HG_obj2 = heterogeneous_Graph(final_HG)\n",
    "\n",
    "# Compute and save patient similarity\n",
    "PS.Patients_Similarity(HG_obj2.HG, HG_obj2.Nodes, base_path)\n",
    "# ===========================================================================================\n",
    "from module1 import reduction as Red\n",
    "\n",
    "# Reduce and save the meta-path similarity matrices\n",
    "Red.Reduction(base_path, PSGs=PSGs_ing)\n",
    "\n",
    "# ===========================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric Difference: ['P', 'lvb', 'L', 'M', 'B', 'D']\n"
     ]
    }
   ],
   "source": [
    "def load_dict_from_pickle(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        loaded_dict = pickle.load(file)\n",
    "    return loaded_dict  \n",
    "b = load_dict_from_pickle('../Data/203_Diagnoses/DMPLB2/500/HGNN_data/edges/final_meta_paths.pkl')\n",
    "a = load_dict_from_pickle('../Data/203_Diagnoses/DMPLB2/500/HGNN_data/As/metapath_list.pkl')\n",
    "\n",
    "symmetric_diff = list(set(a).symmetric_difference(set(b)))\n",
    "print(\"Symmetric Difference:\", symmetric_diff)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
