{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the data\n",
    "1. Generate the Heterogeneous graph\n",
    "2. Generate the feature set from the clinical notes.\n",
    "3. Generate the Labels\n",
    "4. Generate the k-metapath-based similarity matrices\n",
    "5. Convert the As to edge-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class heterogeneous_Graph:\n",
    "    def __init__(self, G):\n",
    "        self.HG = G\n",
    "        Nodes = list(self.HG.nodes())\n",
    "        self.Patients =    [v for v in Nodes if v[0]=='C']\n",
    "        self.Visits =      [v for v in Nodes if v[0]=='V']\n",
    "        self.Medications = [v for v in Nodes if v[0]=='M']\n",
    "        self.Diagnoses  =  [v for v in Nodes if v[0]=='D']\n",
    "        self.Procedures =  [v for v in Nodes if v[0]=='P']\n",
    "        self.Labs       =  [v for v in Nodes if v[0]=='L']\n",
    "        self.MicroBio   =  [v for v in Nodes if v[0]=='B']\n",
    "        self.Nodes = self.Patients  + self.Visits + self.Medications + self.Diagnoses + self.Procedures + self.Labs + self.MicroBio\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 DMPLB2 PC 250 True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "\n",
    "def save_list_as_pickle(L, given_path, file_name):\n",
    "    import pickle\n",
    "    print(f'saving to {given_path}/{file_name}.pkl')\n",
    "    with open(f'{given_path}/{file_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(L, file)\n",
    "\n",
    "# OAK :-)\n",
    "MIMIC_Path        = os.getenv('MIMIC_Path',        '/home/almusawiaf/MyDocuments/PhD_Projects/Data/MIMIC_resources')\n",
    "disease_data_path = os.getenv('disease_data_path', '/home/almusawiaf/MyDocuments/PhD_Projects/HGNN_Project2/Data')\n",
    "\n",
    "# # Check for Athena :-(\n",
    "# MIMIC_Path        = os.getenv('MIMIC_Path', '/home/almusawiaf/MyDocuments/PhD_Projects/Data/MIMIC_resources')\n",
    "# disease_data_path = os.getenv('disease_data_path', '/home/almusawiaf/PhD_Projects/HGNN_Project2/Data')\n",
    "\n",
    "num_Diseases    = int(os.getenv('NUM_DISEASES', 203))  \n",
    "DISEASE_FILE    = os.getenv('DISEASE_FILE', f'DMPLB2')  \n",
    "similarity_type = os.getenv('similarity_type', 'PC')  # options are PC: PathCount, SPS: Symmetric PathSim\n",
    "\n",
    "num_Sample      = int(os.getenv('num_Sample', 250))  \n",
    "r_u_sampling    = os.getenv('r_u_sampling', 'True')  \n",
    "SNF_ing         = os.getenv('SNF_ing', 'False')  \n",
    "\n",
    "\n",
    "if r_u_sampling=='True':\n",
    "    sampling = True\n",
    "else:\n",
    "    sampling = False\n",
    "\n",
    "if SNF_ing=='True':\n",
    "    SNF_ing = True\n",
    "else:\n",
    "    SNF_ing = False\n",
    "\n",
    "print(num_Diseases, DISEASE_FILE, similarity_type, num_Sample, sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================================================\n",
    "saving_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}'\n",
    "\n",
    "for p in ['HGNN_data', 'clinical_items', 'GMLs', 'OHV', 'PSGs', 'SNFs']:\n",
    "    os.makedirs(f'{saving_path}/{p}', exist_ok=True)\n",
    "\n",
    "saving_path = f'{disease_data_path}/{num_Diseases}_Diagnoses/{DISEASE_FILE}/{num_Sample}/HGNN_data'\n",
    "os.makedirs(f'{saving_path}/As', exist_ok=True)\n",
    "# =================================================================================\n",
    "\n",
    "# complete_HG = nx.read_gml(f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating complete HG from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataframes...\n",
      "Splitting lab tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/almusawiaf/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lab_df.loc[:, 'ITEMID_FLAG'] = lab_df['ITEMID'].astype(str) + '_' + lab_df['FLAG'].astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of visits here is 58151\n",
      "Use the patients inside the new DataFrame....\n",
      "Dropping NaN visits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodule1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generating_HG \u001b[38;5;28;01mas\u001b[39;00m gHG\n\u001b[0;32m----> 2\u001b[0m HG_inst \u001b[38;5;241m=\u001b[39m \u001b[43mgHG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerate_HG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMIMIC_Path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m nx\u001b[38;5;241m.\u001b[39mwrite_gml(HG_inst\u001b[38;5;241m.\u001b[39mHG, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdisease_data_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_Diseases\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Diagnoses/complete_HG.gml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m gHG\u001b[38;5;241m.\u001b[39mG_statistics(HG_inst\u001b[38;5;241m.\u001b[39mHG)\n",
      "File \u001b[0;32m~/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:19\u001b[0m, in \u001b[0;36mGenerate_HG.__init__\u001b[0;34m(self, folder_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfolder_path \u001b[38;5;241m=\u001b[39m folder_path\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading the dataframes...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m new_Diagnosis, new_Prescriptions, new_Procedures, new_LabTest, new_MicroBio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_patients_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtracting bipartite networks...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m CV \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_Bipartite(new_Diagnosis,    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECT_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHADM_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVisits\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/MyDocuments/PhD_Projects/HGNN_Project2/Data_Generation2/module1/generating_HG.py:148\u001b[0m, in \u001b[0;36mGenerate_HG.load_patients_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m Medication \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(new_Medication[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrug\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m    147\u001b[0m Diagnosis  \u001b[38;5;241m=\u001b[39m new_Diagnosis[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mICD9_CODE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[0;32m--> 148\u001b[0m LabTests   \u001b[38;5;241m=\u001b[39m \u001b[43mnew_LabTest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mITEMID_FLAG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m MicroBio   \u001b[38;5;241m=\u001b[39m new_MicroBio[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSPEC_ITEMID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGeneral Information:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m---------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:2407\u001b[0m, in \u001b[0;36mSeries.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:  \u001b[38;5;66;03m# pylint: disable=useless-parent-delegation\u001b[39;00m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2346\u001b[0m \u001b[38;5;124;03m    Return unique values of Series object.\u001b[39;00m\n\u001b[1;32m   2347\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[38;5;124;03m    Categories (3, object): ['a' < 'b' < 'c']\u001b[39;00m\n\u001b[1;32m   2406\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/base.py:1025\u001b[0m, in \u001b[0;36mIndexOpsMixin.unique\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     result \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1025\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from module1 import generating_HG as gHG\n",
    "HG_inst = gHG.Generate_HG(MIMIC_Path)\n",
    "nx.write_gml(HG_inst.HG, f'{disease_data_path}/{num_Diseases}_Diagnoses/complete_HG.gml')\n",
    "gHG.G_statistics(HG_inst.HG)\n",
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_inst.Patients)\n",
    "    HG = HG_inst.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_inst.Patients, len(HG_inst.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_inst.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_inst.HG)\n",
    "# ================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole graph or Sample graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HG_obj = heterogeneous_Graph(HG)\n",
    "\n",
    "gHG.G_statistics(HG_obj.HG)\n",
    "\n",
    "# ======================To sample or not to sample, that is the question =========================\n",
    "if not sampling:\n",
    "    num_Sample = len(HG_obj.Patients)\n",
    "    HG = HG_obj.HG\n",
    "else:\n",
    "    patients_to_remove = random.sample(HG_obj.Patients, len(HG_obj.Patients) - num_Sample)\n",
    "    print(len(patients_to_remove), num_Sample, len(HG_obj.Patients))\n",
    "    \n",
    "    # deleting the nodes\n",
    "    HG = gHG.remove_patients_and_linked_visits(patients_to_remove, HG_obj.HG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import XY_preparation as XY\n",
    "# ============================ Extracting Patient-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(HG)\n",
    "X = XY_inst.X\n",
    "Y = XY_inst.Y\n",
    "# ============================ Extracting Visit-based X and Y =================================\n",
    "XY_inst = XY.XY_preparation(HG)\n",
    "XV = XY_inst.X_visit\n",
    "YV = XY_inst.Y_visit\n",
    "# ==================================== Saving X and Y  (patient-based) ============================\n",
    "torch.save(X, f'{saving_path}/X.pt')\n",
    "torch.save(Y, f'{saving_path}/Y.pt')\n",
    "# ==================================== Saving X and Y (visit-based) =================================\n",
    "torch.save(X, f'{saving_path}/XV.pt')\n",
    "torch.save(Y, f'{saving_path}/YV.pt')\n",
    "del X\n",
    "del Y\n",
    "del XV\n",
    "del YV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-path Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import meta_path as MP\n",
    "# ======================= Computing the Meta Path based Similarities ======================\n",
    "MP_inst = MP.Meta_path(HG, similarity_type = 'PC', saving_path = saving_path)\n",
    "# ==================================== SAVING =============================================\n",
    "nx.write_gml(HG, f'{saving_path}/HG.gml')\n",
    "save_list_as_pickle(MP_inst.Nodes,   saving_path, 'Nodes')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module1 import reduction as Red\n",
    "reduction_obj = Red.Reduction(saving_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
